{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Slicing and Views\n",
    "\n",
    "ironArray is meant to store large arrays, but in practice you only want to access single elements or small parts of them.  Here you will learn how to do that with the help of so called *views*.  Views are just references to the part of a larger array that is interesting.\n",
    "\n",
    "Let's start by creating an array in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<IArray (1000, 10000) np.float64>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import iarray as ia\n",
    "\n",
    "dtshape = ia.DTShape((1000, 10000), np.float64)\n",
    "arr = ia.arange(dtshape)\n",
    "arr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now suppose that we just want to access the first 2x2 square.  We just use the NumPy notation for doing this:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<IArray (2,) np.float64>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = arr[0, 0:2]\n",
    "view"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "as you see, we get another `IArray` instance, but a special one: a *view*.  You can always check whether an array is a view or not with the `is_view()` method:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view.is_view()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Of course, our initial array is not a view:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.is_view()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can visualize the data in the view in the same way than a regular `IArray`, i.e. using `ia.iarray2numpy`.  However, there is a handy shortcut for doing the same thing:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.0000e+00, 1.0000e+00],\n       [1.0000e+04, 1.0001e+04]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view.data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In general, it is pretty common to use the `.data` accessor when you want to retrieve the actual data out of an `IArray`:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([    0., 10000., 20000., 30000.])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[:4, 0].data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, retrieving the interesting data out of your IArray is pretty similar to NumPy convention.\n",
    "\n",
    "**Note:** IArray objects support most of the NumPy indexing syntax for getting slices with some exceptions:\n",
    "\n",
    "1) IArray does not have support for strides (the `step` part of slices).\n",
    "\n",
    "2) It does not implement advanced indexing tricks.\n",
    "\n",
    "At any rate, whenever you want to use this functionality, you can always get a NumPy array out of an IArray (or a view of it) and apply your desired indexing there.  Remember that ironArray is meant for handling very large arrays, so there is no shame in getting the interesting slice as a NumPy object and then do your work over it.\n",
    "\n",
    "Finally, indexing also applies to arrays that are stored persistently on disk.  ironArray will use the information about the data you want and will read and decompress only the part that is necessary.  And due to the double partitioning and fast compression codecs, this is in general very fast.  See the `Optimization Tips` section on how to fine-tune the slicing of arrays."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimization Tips\n",
    "\n",
    "ironArray offers two levels of partitioning, the chunk and the block, and that means more degree of flexibility in optimizing I/O when compared to other solutions offering just one single level (Zarr, HDF5...).  In addition, if you don't say anything default values for chunkshape and blockshape (based on CPU's cache sizes).  However, you can still override defaults and fine tune I/O manually.\n",
    "\n",
    "Here it comes a small tutorial on how to do this fine tuning.  Let's start with a large array that is on-disk; as we don't want to use too much disk space, let's use a zero-filled array which compresses very well.  We are going to exercise slicing in two different directions: getting 2 rows and getting 2 columns.  Here it is how this performs:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cratio: 9.2\n",
      "CPU times: user 5.8 ms, sys: 10.4 ms, total: 16.2 ms\n",
      "Wall time: 6.19 ms\n",
      "CPU times: user 2.89 ms, sys: 6.77 ms, total: 9.66 ms\n",
      "Wall time: 3.04 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.4465332 , 0.44580078, 0.44506836, ..., 0.00431442, 0.00447464,\n        0.00463104],\n       [0.44580078, 0.44506836, 0.44433594, ..., 0.00432968, 0.0044899 ,\n        0.0046463 ]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import iarray as ia\n",
    "\n",
    "SHAPE = (10000, 10000)\n",
    "x = np.linspace(1, 10, SHAPE[0])\n",
    "y = np.linspace(1, 10, SHAPE[1])\n",
    "xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "z = np.sin(xx**2 + yy**2) / (xx**2 + yy**2)\n",
    "\n",
    "dtshape = ia.DTShape(SHAPE, np.float64)\n",
    "storage= ia.Storage(urlpath=\"large-arr.iarr\")\n",
    "with ia.config(fp_mantissa_bits=10, storage=storage) as cfg:\n",
    "    arr = ia.numpy2iarray(z, cfg=cfg)\n",
    "print(f\"cratio: {arr.cratio:.1f}\")\n",
    "del x, y, xx, yy\n",
    "\n",
    "%time arr[:, 10:12].data\n",
    "%time arr[10:12, :].data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you see, the total time being smaller than the wall time is an indication of ironArray's parallel reading capabilities.\n",
    "\n",
    "For comparison, let's see how Zarr and HDF5 behaves at doing the same thing:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cratio: 10.0\n",
      "CPU times: user 15.7 ms, sys: 6.04 ms, total: 21.7 ms\n",
      "Wall time: 10.1 ms\n",
      "CPU times: user 7.6 ms, sys: 3.13 ms, total: 10.7 ms\n",
      "Wall time: 5.05 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.4465332 , 0.44580078, 0.44506836, ..., 0.00431442, 0.00447464,\n        0.00463104],\n       [0.44580078, 0.44506836, 0.44433594, ..., 0.00432968, 0.0044899 ,\n        0.0046463 ]])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zarr\n",
    "from numcodecs import Blosc\n",
    "from functools import reduce\n",
    "\n",
    "lz4 = Blosc(\n",
    "    cname=\"lz4\",\n",
    "    clevel=9,\n",
    "    shuffle=Blosc.SHUFFLE,\n",
    "    blocksize=reduce(lambda x, y: x * y, arr.blockshape) * np.dtype(arr.dtype).itemsize,\n",
    ")\n",
    "\n",
    "store = zarr.DirectoryStore('large-arr.zarr')\n",
    "z_arr = zarr.empty(SHAPE, dtype=np.float64, store=store, overwrite=True, compressor=lz4)\n",
    "arr.copyto(z_arr)\n",
    "print(f\"cratio: {z_arr.nbytes / z_arr.nbytes_stored:.1f}\")\n",
    "\n",
    "%time z_arr[:, 10:12]\n",
    "%time z_arr[10:12, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.7 ms, sys: 922 µs, total: 21.7 ms\n",
      "Wall time: 21.7 ms\n",
      "CPU times: user 9.49 ms, sys: 200 µs, total: 9.69 ms\n",
      "Wall time: 9.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.4465332 , 0.44580078, 0.44506836, ..., 0.00431442, 0.00447464,\n        0.00463104],\n       [0.44580078, 0.44506836, 0.44433594, ..., 0.00432968, 0.0044899 ,\n        0.0046463 ]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "f = h5py.File(\"large-arr.hdf5\", \"w\")\n",
    "# We are using LZF codec which is a fast codec distributed with h5py\n",
    "h5_arr = f.create_dataset(\"h5_arr\", SHAPE, dtype=np.float64, chunks=True, compression=\"lzf\", shuffle=True)\n",
    "arr.copyto(h5_arr)\n",
    "\n",
    "data = None\n",
    "%time data = h5_arr[:, 10:12]\n",
    "%time data = h5_arr[10:12, :]\n",
    "f.close()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For further optimization, let's have a look at the chunkshape/blockshape that is assigned automatically to your ironArray array:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "((512, 512), (64, 128))"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.chunkshape, arr.blockshape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's suppose that you prefer to accelerate the access in the **row** direction, and that the row strips will be thin in general (but still, you don't want to penalize accesses in **column** direction too much). In this case, you might want to select a blockshape that stretches more in the row direction (but without making the block too small):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cratio: 2.2\n",
      "CPU times: user 17.3 ms, sys: 20 ms, total: 37.2 ms\n",
      "Wall time: 7.64 ms\n",
      "CPU times: user 2.11 ms, sys: 6.3 ms, total: 8.41 ms\n",
      "Wall time: 3.47 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.44677258, 0.44598785, 0.44520237, ..., 0.00431732, 0.00447622,\n        0.00463364],\n       [0.44598079, 0.44519602, 0.44441049, ..., 0.00433343, 0.00449218,\n        0.00464944]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage = ia.Storage((512, 512), (32, 512), urlpath=\"large-arr-2.iarr\")\n",
    "with ia.config(fp_mantissa_bits=30, storage=storage) as cfg:\n",
    "    arr = ia.numpy2iarray(z, cfg=cfg)\n",
    "print(f\"cratio: {arr.cratio:.1f}\")\n",
    "%time arr[:, 10:12].data\n",
    "%time arr[10:12, :].data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ok, so by just changing the blockshape and adapting it to our read pattern may or *may not* improve the slicing times.  A better bet is adapting both the blockshape *and* the chunkshape as well:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cratio: 2.1\n",
      "CPU times: user 57.3 ms, sys: 78.1 ms, total: 135 ms\n",
      "Wall time: 22.3 ms\n",
      "CPU times: user 1.18 ms, sys: 2.6 ms, total: 3.77 ms\n",
      "Wall time: 2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.44677258, 0.44598785, 0.44520237, ..., 0.00431732, 0.00447622,\n        0.00463364],\n       [0.44598079, 0.44519602, 0.44441049, ..., 0.00433343, 0.00449218,\n        0.00464944]])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage = ia.Storage((128, 2048), (8, 2048), urlpath=\"large-arr-2.iarr\")\n",
    "with ia.config(fp_mantissa_bits=30, storage=storage) as cfg:\n",
    "    arr = ia.numpy2iarray(z, cfg=cfg)\n",
    "print(f\"cratio: {arr.cratio:.1f}\")\n",
    "%time arr[:, 10:12].data\n",
    "%time arr[10:12, :].data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this case, we see that we have been able to get much better speed in the row axis (at the cost of being slower in the column axis).  Finally, let's increase the chunkshape to the maximum in the row axis:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cratio: 2.0\n",
      "CPU times: user 486 ms, sys: 454 ms, total: 940 ms\n",
      "Wall time: 127 ms\n",
      "CPU times: user 787 µs, sys: 649 µs, total: 1.44 ms\n",
      "Wall time: 1.39 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.44677258, 0.44598785, 0.44520237, ..., 0.00431732, 0.00447622,\n        0.00463364],\n       [0.44598079, 0.44519602, 0.44441049, ..., 0.00433343, 0.00449218,\n        0.00464944]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage = ia.Storage((128, 10000), (2, 10000), urlpath=\"large-arr-3.iarr\")\n",
    "with ia.config(fp_mantissa_bits=30, storage=storage) as cfg:\n",
    "    arr = ia.numpy2iarray(z, cfg=cfg)\n",
    "print(f\"cratio: {arr.cratio:.1f}\")\n",
    "%time arr[:, 10:12].data\n",
    "%time arr[10:12, :].data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this case we have been able to reduce the times in the row axis to a bare minimum, but times for column-wise access went up to values that are a bit too much.  What is the best partition configuration largely depends on your needs.  In this case it is pretty clear that we prefer the previous configuration.\n",
    "\n",
    "It is worth noting that compression ratio has been badly affected because of the new partitionings.  In general, when you change the partition shapes, you should expect significant changes in compression ratios.\n",
    "\n",
    "Just for comparison purposes, let's see how a similar configuration affects to Zarr and HDF5:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cratio: 2.0\n",
      "CPU times: user 87.7 ms, sys: 35.9 ms, total: 124 ms\n",
      "Wall time: 57.3 ms\n",
      "CPU times: user 9.1 ms, sys: 2.75 ms, total: 11.8 ms\n",
      "Wall time: 4.97 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.44677258, 0.44598785, 0.44520237, ..., 0.00431732, 0.00447622,\n        0.00463364],\n       [0.44598079, 0.44519602, 0.44441049, ..., 0.00433343, 0.00449218,\n        0.00464944]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = zarr.DirectoryStore('large-arr-2.zarr')\n",
    "z_arr = zarr.empty(SHAPE, dtype=np.float64, store=store, overwrite=True, chunks=(128, 2048), compressor=lz4)\n",
    "arr.copyto(z_arr)\n",
    "print(f\"cratio: {z_arr.nbytes / z_arr.nbytes_stored:.1f}\")\n",
    "\n",
    "%time z_arr[:, 10:12]\n",
    "%time z_arr[10:12, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 215 ms, sys: 16.4 ms, total: 231 ms\n",
      "Wall time: 231 ms\n",
      "CPU times: user 13.6 ms, sys: 1.37 ms, total: 15 ms\n",
      "Wall time: 15 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.44677258, 0.44598785, 0.44520237, ..., 0.00431732, 0.00447622,\n        0.00463364],\n       [0.44598079, 0.44519602, 0.44441049, ..., 0.00433343, 0.00449218,\n        0.00464944]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File(\"large-arr-2.hdf5\", \"w\")\n",
    "h5_arr = f.create_dataset(\"h5_arr\", SHAPE, dtype=np.float64, chunks=(128, 2048), compression=\"lzf\", shuffle=True)\n",
    "arr.copyto(h5_arr)\n",
    "\n",
    "data = None\n",
    "%time data = h5_arr[:, 10:12]\n",
    "%time data = h5_arr[10:12, :]\n",
    "f.close()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, we see that ironArray, by providing two levels of partitioning, it has more fine-grained flexibility in adapting to different I/O patterns.  Also, this two-level partitions allow for better reducing the number of data read from disk (or memory) than similar solutions with just one level partitioning.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, we see that ironArray, by providing two levels of partitioning, it has more fine-grained flexibility in adapting to different I/O patterns.  Also, this two-level partitions allow for better reducing the number of data read from disk (or memory) than similar solutions with just one level partitioning.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}