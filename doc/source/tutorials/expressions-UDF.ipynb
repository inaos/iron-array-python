{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expression Evaluation (User Defined Functions)\n",
    "\n",
    "So far we have seen that ironArray has support for evaluating expressions that are passed as strings or as simple Python statements.  There is another, more flexible way for evaluating expressions called User Defined Functions, or UDFs for short.\n",
    "\n",
    "UDFs are small functions that can be expressed in a simple subset of Python.  These functions are then passed to the internal LLVM compiler in ironArray and a binary specific and optimized for the local machine is generated.  This binary is optimized for the CPU and in addition, it will make use of the [Intel SVML library](https://software.intel.com/content/www/us/en/develop/documentation/cpp-compiler-developer-guide-and-reference/top/compiler-reference/intrinsics/intrinsics-for-short-vector-math-library-operations/overview-intrinsics-for-short-vector-math-library-svml-functions.html) for accelerating the evaluation of transcendental functions.\n",
    "\n",
    "Let's see how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memprofiler\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import iarray as ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.8 s, sys: 4.82 s, total: 31.6 s\n",
      "Wall time: 6.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "precip1 = ia.load(\"precip1.iarr\")\n",
    "precip2 = ia.load(\"precip2.iarr\")\n",
    "precip3 = ia.load(\"precip3.iarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, let's define a simple function that computes the mean for this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from iarray.udf import jit, Array, float32\n",
    "\n",
    "@jit()\n",
    "def mean(out: Array(float32, 3),\n",
    "         p1: Array(float32, 3),\n",
    "         p2: Array(float32, 3),\n",
    "         p3: Array(float32, 3)) -> int:\n",
    "\n",
    "    l = p1.shape[0]\n",
    "    m = p1.shape[1]\n",
    "    n = p1.shape[2]\n",
    "\n",
    "    for i in range(l):\n",
    "        for j in range(m):\n",
    "            for k in range(n):\n",
    "                value = p1[i,j,k] + p2[i,j,k] + p3[i,j,k]\n",
    "                out[i,j,k] = value / 3\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and create the ironArray expression from this User Defined Function with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.2 ms, sys: 9.27 ms, total: 31.5 ms\n",
      "Wall time: 43.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "precip_expr = ia.expr_from_udf(mean, [precip1, precip2, precip3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As can be seen, converting the user defined function into a native ironArray expression is pretty fast.  And as always, in order to do the actual evaluation, we have to call `.eval()` on the expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IArray (720, 721, 1440) np.float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memprofiler: used 435.21 MiB RAM (peak of 491.55 MiB) in 1.0935 s, total RAM usage 1549.15 MiB\n"
     ]
    }
   ],
   "source": [
    "%%mprof_run iarray-mean\n",
    "precip_mean = precip_expr.eval()\n",
    "precip_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this time with the evaluation via a regular lazy expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_expr2 = (precip1 + precip2 + precip3) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IArray (720, 721, 1440) np.float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memprofiler: used 382.66 MiB RAM (peak of 453.57 MiB) in 1.1170 s, total RAM usage 1931.82 MiB\n"
     ]
    }
   ],
   "source": [
    "%%mprof_run iarray-mean2\n",
    "precip_mean2 = precip_expr2.eval()\n",
    "precip_mean2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the times are very close.  It turns out that UDFs compile and execute in ironArray using the very same LLVM machinery, which explains times being similar.  It is up to the user to use one or the other depending on the needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, let's use expressions with some transcendental functions.  This does not make sense for this case (precipitation data), but we are doing this just as an indication of the efficiency of the computational engine inside ironArray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "@jit()\n",
    "def trans(out: Array(float32, 3),\n",
    "          p1: Array(float32, 3),\n",
    "          p2: Array(float32, 3),\n",
    "          p3: Array(float32, 3)) -> int:\n",
    "\n",
    "    l = p1.shape[0]\n",
    "    m = p1.shape[1]\n",
    "    n = p1.shape[2]\n",
    "\n",
    "    for i in range(l):\n",
    "        for j in range(m):\n",
    "            for k in range(n):\n",
    "                value = math.sin(p1[i,j,k]) * math.sin(p2[i,j,k]) + math.cos(p2[i,j,k])\n",
    "                value *= math.tan(p1[i,j,k])\n",
    "                value += math.sqrt(p3[i,j,k]) * 2\n",
    "                out[i,j,k] = value\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.8 ms, sys: 5.34 ms, total: 27.2 ms\n",
      "Wall time: 39 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "precip_expr = ia.expr_from_udf(trans, [precip1, precip2, precip3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IArray (720, 721, 1440) np.float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memprofiler: used 645.20 MiB RAM (peak of 718.22 MiB) in 1.2722 s, total RAM usage 2579.38 MiB\n"
     ]
    }
   ],
   "source": [
    "%%mprof_run iarray-trans\n",
    "precip_mean = precip_expr.eval()\n",
    "precip_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this case we see that the overhead of using transcendental functions is pretty the same than plain arithmetic operations (sum, rest, mult, division...).  This is a very significant fact because traditionally transcendental functions took really long time compared with plain arithmetic; not anymore thanks to SVML.  Let's compare these times against NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 s, sys: 2.12 s, total: 13.3 s\n",
      "Wall time: 4.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p1_ = precip1.data\n",
    "p2_ = precip2.data\n",
    "p3_ = precip3.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%mprof_run np_trans\n",
    "np_result = (np.tan(p1_) * (np.sin(p1_) * np.sin(p2_) + np.cos(p2_)) + np.sqrt(p3_) * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is really slow, but this is kind of expected because NumPy does not have support for SVML (at this time at least), and we all know that transcendental functions always took quite a lot to execute on a regular CPU.  The secret behind SVML is a good mix between compiler optimization (via LLVM) and SIMD usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Compare with numba"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
