{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expression Evaluation (User Defined Functions)\n",
    "\n",
    "So far we have seen that ironArray has support for evaluating expressions that are passed as strings or as simple Python statements.  There is another, more flexible way for evaluating expressions called User Defined Functions, or UDFs for short.\n",
    "\n",
    "UDFs are small functions that can be expressed in a simple subset of Python.  These functions are then passed to the internal LLVM compiler in ironArray and a binary specific and optimized for the local machine is generated.  This binary is optimized for the CPU and in addition, it will make use of the [Intel SVML library](https://software.intel.com/content/www/us/en/develop/documentation/cpp-compiler-developer-guide-and-reference/top/compiler-reference/intrinsics/intrinsics-for-short-vector-math-library-operations/overview-intrinsics-for-short-vector-math-library-svml-functions.html) for accelerating the evaluation of transcendental functions.\n",
    "\n",
    "Let's see how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memprofiler\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import iarray as ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 106 ms, sys: 201 ms, total: 308 ms\n",
      "Wall time: 308 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "precip1 = ia.load(\"precip1.iarr\")\n",
    "precip2 = ia.load(\"precip2.iarr\")\n",
    "precip3 = ia.load(\"precip3.iarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, let's define a simple function that computes the mean for this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from iarray.udf import jit, Array, float32, float64\n",
    "\n",
    "@jit()\n",
    "def mean(out: Array(float32, 3),\n",
    "         p1: Array(float32, 3),\n",
    "         p2: Array(float32, 3),\n",
    "         p3: Array(float32, 3)) -> int:\n",
    "\n",
    "    l = out.shape[0]\n",
    "    m = out.shape[1]\n",
    "    n = out.shape[2]\n",
    "\n",
    "    for i in range(l):\n",
    "        for j in range(m):\n",
    "            for k in range(n):\n",
    "                value = p1[i,j,k] + p2[i,j,k] + p3[i,j,k]\n",
    "                out[i,j,k] = value / 3\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is known as a _User Defined Function_ (_UDF_ for short) and it has a syntax that is a small subset of Python.  The order of the parameters passed matters: first comes the output and then a variable number of inputs (3 in this case).  The type of the parameters is always an `Array`, where you specify the data type (currently `float32` or `float64`), and the dimensions (3 in this case).\n",
    "\n",
    "Finally, you can make use of the `shape` attribute of the parameters so as to access the _window_ to which the UDF will apply.  It is important to have in mind that the parameters do not have access to whole arrays passed to the function, but only to one part (also known as _window_).  Later we will see an example where we will work more explictly with windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the ironArray expression from this User Defined Function with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.2 ms, sys: 4.46 ms, total: 27.7 ms\n",
      "Wall time: 27.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "precip_expr = ia.expr_from_udf(mean, [precip1, precip2, precip3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As can be seen, converting the user defined function into a native ironArray expression is pretty fast.  And as always, in order to do the actual evaluation, we have to call `.eval()` on the expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IArray (720, 721, 1440) np.float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memprofiler: used 496.22 MiB RAM (peak of 496.22 MiB) in 0.7525 s, total RAM usage 1376.03 MiB\n"
     ]
    }
   ],
   "source": [
    "%%mprof_run iarray-mean\n",
    "precip_mean = precip_expr.eval()\n",
    "precip_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this time with the evaluation via a regular lazy expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_expr2 = (precip1 + precip2 + precip3) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IArray (720, 721, 1440) np.float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memprofiler: used 393.84 MiB RAM (peak of 393.84 MiB) in 0.7497 s, total RAM usage 1769.88 MiB\n"
     ]
    }
   ],
   "source": [
    "%%mprof_run iarray-mean2\n",
    "precip_mean2 = precip_expr2.eval()\n",
    "precip_mean2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the times and memory consumption are very close.  It turns out that UDFs compile and execute in ironArray using the very same LLVM machinery, which explains times being similar.  It is up to the user to decide to use one or the other depending on the needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "User Defined Function also have access to a good assortment of math functions, and you can access them via the usual Python `math` module. Let's see an example for our dataset, and although this does not make much sense for precipitation data, we can use this as an indication of the efficiency of the computational engine inside ironArray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "@jit()\n",
    "def trans(out: Array(float32, 3),\n",
    "          p1: Array(float32, 3),\n",
    "          p2: Array(float32, 3),\n",
    "          p3: Array(float32, 3)) -> int:\n",
    "\n",
    "    l = out.shape[0]\n",
    "    m = out.shape[1]\n",
    "    n = out.shape[2]\n",
    "\n",
    "    for i in range(l):\n",
    "        for j in range(m):\n",
    "            for k in range(n):\n",
    "                value = math.sin(p1[i,j,k]) * math.sin(p2[i,j,k]) + math.cos(p2[i,j,k])\n",
    "                value *= math.tan(p1[i,j,k])\n",
    "                value += math.sqrt(p3[i,j,k]) * 2\n",
    "                out[i,j,k] = value\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.7 ms, sys: 4.94 ms, total: 24.6 ms\n",
      "Wall time: 24.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "precip_expr = ia.expr_from_udf(trans, [precip1, precip2, precip3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IArray (720, 721, 1440) np.float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memprofiler: used 650.31 MiB RAM (peak of 650.31 MiB) in 1.1076 s, total RAM usage 2420.74 MiB\n"
     ]
    }
   ],
   "source": [
    "%%mprof_run iarray-trans\n",
    "precip_mean = precip_expr.eval()\n",
    "precip_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this case we see that the overhead of using transcendental functions is pretty the same than plain arithmetic operations (sum, rest, mult, division...).  This is a very significant fact because traditionally transcendental functions took really long time compared with plain arithmetic; not anymore thanks to the combination of LLVML and Intel SVML.  The good mix between compiler optimization (via LLVM) and SIMD usage (via SVML) makes this couple shine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of comparison, let's compute the same expression with NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 1.87 s, total: 12.4 s\n",
      "Wall time: 4.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p1_ = precip1.data\n",
    "p2_ = precip2.data\n",
    "p3_ = precip3.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memprofiler: used 2852.12 MiB RAM (peak of 8555.11 MiB) in 8.4781 s, total RAM usage 13842.86 MiB\n"
     ]
    }
   ],
   "source": [
    "%%mprof_run np_trans\n",
    "np_result = (np.tan(p1_) * (np.sin(p1_) * np.sin(p2_) + np.cos(p2_)) + np.sqrt(p3_) * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is really slow, but this is kind of expected because NumPy does not have support for SVML or multithreading (at this time at least), and we all know that transcendental functions always took quite a lot to execute on a regular CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with data windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already mentioned that User Defined Functions can access only a part (a window) of the dataset.  Here we will have a more in deep look at how this works and how to squeeze all the functionality out of it.\n",
    "\n",
    "Let's start by creating an zeroed array, and let's populate it with a UDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ia.zeros((10, 10), chunks=(5, 5), blocks=(2, 2), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UDF used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def fill_diag(out: Array(float64, 2), in1: Array(float64, 2)) -> int:\n",
    "    n = out.shape[0]\n",
    "    m = out.shape[1]\n",
    "    start_n = out.window_start[0]\n",
    "    start_m = out.window_start[1]\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            out[i, j] = 1. if i + start_n == j + start_m else in1[i, j]\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_expr = ia.expr_from_udf(fill_diag, [e])\n",
    "result = fill_expr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
