{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expressions\n",
    "\n",
    "ironArray has a strong support for expression evaluation.  Things like sums, products, divisions or a pretty complete range of transcendental functions (e.g. `exp`, `sin`, `asin`, `tanh`...).  Fast evaluation of (large) arrays is one of the features that received more love during the development.  Performance comes from a balance between:\n",
    "\n",
    "1. Use of [Intel MKL](https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/onemkl.html) for accelerating transcendental functions.\n",
    "\n",
    "2. Use of [Intel SVML](https://software.intel.com/content/www/us/en/develop/documentation/cpp-compiler-developer-guide-and-reference/top/compiler-reference/intrinsics/intrinsics-for-short-vector-math-library-operations/overview-intrinsics-for-short-vector-math-library-svml-functions.html) for computing vector math functions.\n",
    "\n",
    "3. Use of multi-threading capabilities.\n",
    "\n",
    "4. Leveraging the 2-level partitioning in ironArray arrays so that most of the computation intensive happens inside private caches (L1, L2), which benefits multi-threading performance.\n",
    "\n",
    "You can access to the powerful evaluation capabilities in ironArray in different ways, which we are going to succinctly expose in this tutorial.  In order to do that, we are going to make use of the dataset that we created in our reductions tutorial.  Let's go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 395 ms, sys: 117 ms, total: 512 ms\n",
      "Wall time: 686 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import iarray as ia\n",
    "ia_precip = ia.load(\"precip-3m.iarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, in order to evaluate some expressions on this, let's put the data for each month on a different array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 128)\n",
      "(1, 16, 16, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IArray (3, 720, 721, 1440) np.float32>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ia_precip.chunkshape)\n",
    "print(ia_precip.blockshape)\n",
    "ia_precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 s, sys: 5.41 s, total: 25 s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "precip1 = ia_precip[0].copy()\n",
    "precip2 = ia_precip[1].copy()\n",
    "precip3 = ia_precip[2].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With that, let's compute something easy, like a new array with the mean of these.  For that, we are going to use the internal evaluation engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.8 ms, sys: 2.16 ms, total: 21 ms\n",
      "Wall time: 21 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "<iarray.expression.Expr at 0x7f9090b03900>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "precip_expr = ia.expr_from_string(\"(p1 + p2 + p3) / 3\", {'p1': precip1, 'p2': precip2, 'p3': precip3})\n",
    "precip_expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ok, that was fast, but we did not quite evaluate anything yet; we rather build the expression to compute.  This way you can combine different expressions (made of possible views) and delay the actual evaluation only when necessary (TODO: is that really possible?).\n",
    "\n",
    "In order to do the actual evaluation, we have to call `.eval()` on a expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 2.68 s, total: 13.1 s\n",
      "Wall time: 1.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IArray (720, 721, 1440) np.float32>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "precip_mean = precip_expr.eval()\n",
    "precip_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Cool, so we have our first evaluation done.  But let's see how its performance fares against NumPy, and especially whether the outcome is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np_precip1 = precip1.data\n",
    "np_precip2 = precip2.data\n",
    "np_precip3 = precip3.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 566 ms, total: 1.79 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np_precip_mean = (np_precip1 + np_precip2 + np_precip3) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So, ironArray times are quite competitive with NumPy (several times faster, in fact).  How about the correctness of the outcome?.  Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.testing.assert_almost_equal(np_precip_mean, precip_mean.data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Cool, results are the same. That means that, generally speaking, ironArray can go faster than NumPy operations, even if the former are compressed.  But let's see how it performs against a parallel evaluation engine like `numexpr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.66 s, sys: 14.6 s, total: 18.3 s\n",
      "Wall time: 2.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numexpr as ne\n",
    "np_precip_mean = ne.evaluate(\"(p1 + p2 + p3) / 3\", {'p1': np_precip1, 'p2': np_precip2, 'p3': np_precip3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As you see, ironArray performance is very close to numexpr too and, again, remember that ironArray is dealing with compressed data transparently.\n",
    "\n",
    "Now, let's use expressions with some transcendental functions.  This does not make sense for precipitation data, but just as an indication of the speed of ironArray in this area too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.3 s, sys: 4.66 s, total: 22.9 s\n",
      "Wall time: 2.72 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IArray (720, 721, 1440) np.float32>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result = ia.expr_from_string(\"(tan(p1) * (sin(p1) * sin(p2) + cos(p2)) + sqrt(p3) * 2)\",\n",
    "                             {'p1': precip1, 'p2': precip2, 'p3': precip3}\n",
    "                             ).eval()\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "and let's compare this against NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 7.69 s, total: 19.8 s\n",
      "Wall time: 20.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#import numpy as np\n",
    "p1_ = np_precip1\n",
    "p2_ = np_precip2\n",
    "p3_ = np_precip3\n",
    "np_result = (np.tan(p1_) * (np.sin(p1_) * np.sin(p2_) + np.cos(p2_)) + np.sqrt(p3_) * 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ok, this is really slow.  Let's see how numexpr performs in this case:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 1.61 s, total: 12.6 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#import numexpr as ne\n",
    "#ne.set_num_threads(0)\n",
    "np_result = ne.evaluate(\"(tan(p1) * (sin(p1) * sin(p2) + cos(p2)) + sqrt(p3) * 2)\",\n",
    "                        {'p1': np_precip1, 'p2': np_precip2, 'p3': np_precip3})"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again, this time is close to what we are getting with ironArray.  Do not forget to check for correctness:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.testing.assert_almost_equal(np_result, np_result.data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "TODO: Introduce lazy expressions and UDFs, and an 'Optimization tips' section...\n",
    "\n",
    "TODO: add a comparison with xarray or dask, for out-of-core reductions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}