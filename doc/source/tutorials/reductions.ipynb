{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reductions\n",
    "\n",
    "ironArray supports a broad range of reduction facilities, like `sum`, `min`, `max`, `mean` and others.  Also, they work on any (or group of) dimensions.  One interesting aspect of these is that the implementation leverages the multi-threading capabilities of ironArray, so they can be pretty fast (although some times they need some help from the user).\n",
    "\n",
    "In order to exercise some of this functionality, let's download some open data from the network.  In this case, we are interested in downloading precipitation data from a period of 3 months.  With a decent connection, this should not take more than a minute to download.  Let's go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import s3fs\n",
    "import iarray as ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def open_zarr(year, month, datestart, dateend):\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "    datestring = 'era5-pds/zarr/{year}/{month:02d}/data/'.format(year=year, month=month)\n",
    "\n",
    "    precip_zarr = xr.open_dataset(s3fs.S3Map(datestring + 'precipitation_amount_1hour_Accumulation.zarr/',\n",
    "                                             s3=fs),\n",
    "                                 engine=\"zarr\")\n",
    "    precip_zarr = precip_zarr.sel(time1=slice(np.datetime64(datestart), np.datetime64(dateend)))\n",
    "\n",
    "    return precip_zarr.precipitation_amount_1hour_Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 381 ms, sys: 16 ms, total: 397 ms\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "precip_m1 = open_zarr(1987, 10, '1987-10-01', '1987-10-30 23:59')\n",
    "precip_m2 = open_zarr(1987, 11, '1987-11-01', '1987-11-30 23:59')\n",
    "precip_m3 = open_zarr(1987, 12, '1987-12-01', '1987-12-30 23:59')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how one of these arrays of monthly precipitation looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<xarray.DataArray 'precipitation_amount_1hour_Accumulation' (time1: 720, lat: 721, lon: 1440)>\\n[747532800 values with dtype=float32]\\nCoordinates:\\n  * lat      (lat) float32 90.0 89.75 89.5 89.25 ... -89.25 -89.5 -89.75 -90.0\\n  * lon      (lon) float32 0.0 0.25 0.5 0.75 1.0 ... 359.0 359.2 359.5 359.8\\n  * time1    (time1) datetime64[ns] 1987-10-01 ... 1987-10-30T23:00:00\\nAttributes:\\n    long_name:       Total precipitation\\n    nameCDM:         Total_precipitation_1hour_Accumulation\\n    nameECMWF:       Total precipitation\\n    product_type:    forecast\\n    shortNameECMWF:  tp\\n    standard_name:   precipitation_amount\\n    units:           m\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(precip_m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so that's about 3 GB per month, so the full dataset is about 9 GB.\n",
    "\n",
    "Now, let's build a NumPy array out of these (be careful if you plan to run this in your local machine, as you will need at least 16 GB of free memory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 2.19 s, total: 15.6 s\n",
      "Wall time: 22.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 720, 721, 1440)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "precip = np.stack((precip_m1.values, precip_m2.values, precip_m3.values))\n",
    "precip.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, let's suppose that we want to compute the mean for the precipitation per hour during our period of time.  As the time axis is 1 in our new `precip` array, we want to reduce on all axis, except the first.  That is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 788 ms, sys: 0 ns, total: 788 ms\n",
      "Wall time: 788 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reduc0 = np.mean(precip, axis=(0, 2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ok.  Now, let's import this data into ironArray before proceeding with reductions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IArray (3, 720, 721, 1440) np.float32>\n",
      "cratio:  23.46\n",
      "CPU times: user 20.6 s, sys: 3.41 s, total: 24 s\n",
      "Wall time: 7.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ia_precip = ia.numpy2iarray(precip)\n",
    "print(ia_precip)\n",
    "print(\"cratio: \", round(ia_precip.cratio, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ok, so ironArray achieves a compression ratio of around 20x, which is a big win in terms of memory consumption.  Now, let's have a look at how reduction works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 52s, sys: 392 ms, total: 4min 53s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reduc1 = ia.mean(ia_precip, axis=(0, 2, 3)).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ok, so that's pretty slow.  Now, it is time to remember that ironArray uses chunked storage, even when it holds data in-memory.  In this case, we have been traversing the array in a very innefficient way.  In general, in chunked storage, it is always better to start reducing by the dimension that is the largest, and we took the inverse order.  With this in mind, let's try with a more reasonable order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.83 s, sys: 212 ms, total: 10 s\n",
      "Wall time: 678 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reduc1 = ia.mean(ia_precip, axis=(3, 2, 0)).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ok, that's much better.  This time is pretty competitive.  Now, let's compare actual data with NumPy (just in case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(reduc0, reduc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ok, so the mean calculation has worked correctly.\n",
    "\n",
    "If you need to compute this sort of reductions lots of times, you may want to fine tune your ironArray array parameters.  If so, just keep reading.  But before proceeding further, let's save our data for later reuse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ia_precip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ia_precip' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ia.save(ia_precip[0].copy(), \"precip1.iarr\")\n",
    "ia.save(ia_precip[1].copy(), \"precip2.iarr\")\n",
    "ia.save(ia_precip[2].copy(), \"precip3.iarr\")\n",
    "ia.save(ia_precip, \"precip-3m.iarr\")\n",
    "%ls -lh precip*.iarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The dataset is stored now on a single file of 440 MB, which is more than 20x less than the original dataset thanks to compression.  That's a big win!\n",
    "\n",
    "Finally, let's save the data in zarr format for other tutorials too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1G\tprecip-3m.zarr\n",
      "363M\tprecip1.zarr\n",
      "357M\tprecip2.zarr\n",
      "355M\tprecip3.zarr\n",
      "CPU times: user 7.85 s, sys: 795 ms, total: 8.65 s\n",
      "Wall time: 3.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "zarr.save(\"precip1.zarr\", precip_m1.values)\n",
    "zarr.save(\"precip2.zarr\", precip_m2.values)\n",
    "zarr.save(\"precip3.zarr\", precip_m3.values)\n",
    "!du -sh precip*.zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optimization Tips\n",
    "\n",
    "As we know, most of ironArray optimization stems from their two levels of partitioning.  Previously, we have been using automatic values for chunkshape and blockshape (based on CPU's cache sizes).  But for maximum speed, there is no replacement for fine tuning chunk and block shapes manually.\n",
    "\n",
    "Let's start by loading the array that we previously stored on-disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.22 ms, sys: 13 ms, total: 17.2 ms\n",
      "Wall time: 12.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import iarray as ia\n",
    "ia_precip = ia.open(\"precip-3m.iarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So, not too much for loading a 9 GB large array from disk, uh?  Well, the thing is that `open()` just loads data when it needs it by default (but for a full in-memory load, see the `load()` function).  So, only a tiny portion of the file (the metadata) is read in order to figure out how access the data.\n",
    "\n",
    "Now, let's see the current chunk and block shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 512)\n",
      "(1, 16, 16, 128)\n"
     ]
    }
   ],
   "source": [
    "print(ia_precip.chunkshape)\n",
    "print(ia_precip.blockshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, let's start with a first attempt to find out the chunk and block shapes that can optimize the reductions.  Initially one may think that making the last dimension (the largest) as large as possible could be good decision.  Let's try that by creating another container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.6 s, sys: 1.01 s, total: 27.6 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with ia.config(chunkshape=(1, 64, 64, 1440), blockshape=(1, 16, 16, 360)) as cfg:\n",
    "    new_precip = ia_precip.copy(cfg=cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And let's try the reduction with the new array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.29 s, sys: 503 ms, total: 8.79 s\n",
      "Wall time: 992 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reduc1 = ia.mean(new_precip, axis=(3, 2, 0)).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Well, we have got some improvement, which is not bad for a first attempt.  After several iterations, one can reach a sort of optimal configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 2.41 s, total: 23.9 s\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with ia.config(chunkshape=(1, 360, 128, 1440), blockshape=(1, 8, 8, 720)) as cfg:\n",
    "    new_precip = ia_precip.copy(cfg=cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.11 s, sys: 69.4 ms, total: 9.18 s\n",
      "Wall time: 503 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reduc1 = ia.mean(new_precip, axis=(3, 2, 0)).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So, this new time is competitive with NumPy (somewhat better in fact).  That means that, when you have to deal with large arrays you should not assume that working with NumPy arrays is the fast thing you can get.  With the right tools, and a bit of manual tuning, you can end with very fast solutions for this scenario too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressions with on-disk operands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have been playing with expressions on in-memory operands, but ironArray can seamlessly work with on-disk arrays too.  Let's save the previous array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 862 µs, sys: 219 ms, total: 220 ms\n",
      "Wall time: 220 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ia.save(new_precip, \"precip-3m-optimal.iarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "and let's re-open again but in 'lazy' mode and do the reduction from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "IArrayError",
     "evalue": "b'BLOSC FAILED - 0x800a0000002b040b - error=1,ver=0,rev=10,os=0,neg=0,adj=43,subject=1035,code=2818048,ubits=0x0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIArrayError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-ad4b070e3a73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_precip_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precip-3m-optimal2.iarr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnew_precip_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/inaos/iron-array-python/iarray/utils.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, cfg, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32miarray_ext.pyx\u001b[0m in \u001b[0;36miarray.iarray_ext.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32miarray_ext.pyx\u001b[0m in \u001b[0;36miarray.iarray_ext.iarray_check\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIArrayError\u001b[0m: b'BLOSC FAILED - 0x800a0000002b040b - error=1,ver=0,rev=10,os=0,neg=0,adj=43,subject=1035,code=2818048,ubits=0x0'"
     ]
    }
   ],
   "source": [
    "new_precip_opt = ia.open(\"precip-3m-optimal.iarr\")\n",
    "new_precip_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_precip_opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_precip_opt' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reduc1 = ia.mean(new_precip_opt, axis=(3, 2, 0)).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So, although this on-disk time is considerable slower than the in-memory one, it is still not bad.  This is interesting because that means that doing out-of-core operations on modern SSDs (our case here) will consume far less memory, while still keeping reasonable times.\n",
    "\n",
    "TODO: add a comparison with xarray or dask, for out-of-core reductions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
